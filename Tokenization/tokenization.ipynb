{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "#### Tokenization in NLP is the process of breaking down a text into smaller units called tokens. These tokens can be words, characters, or subwords, depending on the specific application and algorithm used. This step is crucial for preparing text for machine learning models, as models require numerical data as input. \n",
    "\n",
    "\n",
    "## Tokenization terms \n",
    "\n",
    "### Corpus\n",
    "\n",
    "#### A **corpus** is simply a large, organized collection of text used for analysis. Imagine it as the entire body of text you're studying. For example, if you're analyzing a company's communications, all their financial reports, press releases, and internal memos combined would form your corpus.\n",
    "\n",
    "### Documents\n",
    "\n",
    "#### Within a corpus, individual pieces of text are called **documents**. A document is a self-contained unit of information. In our company example, each individual financial report or even a specific paragraph within a report could be considered a document.\n",
    "\n",
    "### Sentences\n",
    "\n",
    "#### Sometimes, for more granular analysis, each **sentence** can also be treated as a document. This is useful when you need to analyze very small chunks of information.\n",
    "\n",
    "### Vocabulary\n",
    "\n",
    "#### The **vocabulary** of your corpus is the complete set of all unique words found across all your documents. It's like a dictionary of every single distinct word you've encountered.\n",
    "\n",
    "### Words\n",
    "\n",
    "#### Finally, **words** are the individual building blocks of your text. These are the single terms or tokens that make up your documents and, collectively, form your vocabulary.\n",
    "\n",
    "#### In Short \n",
    "##### Corpus: All financial reports combined.\n",
    "##### Documents: Each report or paragraph in the corpus.\n",
    "##### Vocabulary: The set of unique words across all documents.\n",
    "##### Words: Individual terms used in each document."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
